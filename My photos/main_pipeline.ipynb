
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Sepsis Prediction Pipeline (GRU-D, T-LSTM, Fusion Model)\n",
    "This notebook sets up everything automatically on Colab. Just run all cells sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 1: Install required libraries\n",
    "!pip install transformers torch torchvision torchaudio scikit-learn pandas numpy matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 2: Create required folders\n",
    "import os\n",
    "folders = ['data', 'src/models', 'src/utils', 'notebooks']\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "print("Project structure initialized âœ…")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 3: Download core Python scripts from your repo or inject here\n",
    "# For this demo, we simulate creating required files\n",
    "# Replace these with GitHub URLs if your files are online\n",
    "from pathlib import Path\n",
    "\n",
    "# Example: Create dummy GRU-D model file\n",
    "Path('src/models/gru_d.py').write_text('''\nimport torch\nimport torch.nn as nn\n\nclass GRUD(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size=2):\n        super(GRUD, self).__init__()\n        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n        self.output = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, mask, delta, x_last):\n        out, _ = self.rnn(x)\n        return self.output(out[:, -1, :])\n''')\n",
    "print("Core model files created âœ…")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 4: Generate synthetic data\n",
    "import numpy as np\n",
    "np.save('data/vitals_X.npy', np.random.rand(100, 48, 75))\n",
    "np.save('data/mask_X.npy', np.random.randint(0, 2, (100, 48, 75)))\n",
    "np.save('data/labels_y.npy', np.random.randint(0, 2, (100, 48)))\n",
    "import pandas as pd\n",
    "pd.DataFrame({'note': ["Patient stable" for _ in range(100)]}).to_csv('data/notes.csv', index=False)\n",
    "print("Synthetic data generated âœ…")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 5: Minimal preprocessing script\n",
    "Path('src/utils/preprocessing.py').write_text('''\nimport numpy as np\nimport torch\n\ndef compute_mask(data):\n    return ~np.isnan(data)\n\ndef compute_delta(mask):\n    return np.random.rand(*mask.shape)\n\ndef forward_fill(data):\n    return np.nan_to_num(data)\n\ndef preprocess():\n    vitals = np.load("data/vitals_X.npy")\n    mask = compute_mask(vitals)\n    delta = compute_delta(mask)\n    x_last = forward_fill(vitals)\n    labels = np.load("data/labels_y.npy")\n    return dict(vitals=torch.tensor(vitals).float(),\n                mask=torch.tensor(mask).float(),\n                delta=torch.tensor(delta).float(),\n                x_last_observed=torch.tensor(x_last).float(),\n                labels=torch.tensor(labels).long())\n''')\n",
    "print("Preprocessing script ready âœ…")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 6: Train GRU-D\n",
    "from src.models.gru_d import GRUD\n",
    "from src.utils import preprocessing\n",
    "import torch.optim as optim\n",
    "\n",
    "data = preprocessing.preprocess()\n",
    "model = GRUD(input_size=75, hidden_size=64)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data['vitals'], data['mask'], data['delta'], data['x_last_observed'])\n",
    "    labels = data['labels'][:, -1]\n",
    "    loss = criterion(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f"Epoch {epoch+1} loss: {loss.item():.4f}")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
